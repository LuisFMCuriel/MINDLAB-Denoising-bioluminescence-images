{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a2b4a2",
   "metadata": {},
   "source": [
    "# **1. Clone repository**\n",
    "---\n",
    "Cloning the repository will give you access to the model and scripts we will use for denoising. After the operation is finished, you will find the files and models in the **Files** tab on the top left of notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3555decc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/LuisFMCuriel/MINDLAB-Denoising-bioluminescence-images.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed2afc",
   "metadata": {},
   "source": [
    "# **1.2. Install CSBDeep for CARE and import dependencies**\n",
    "---\n",
    "By default a few libriaries are not installed in the google colab environment. Running this cell will ensure the libraries we need for denoising are fully operational and imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d6a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown ##Install CARE and dependencies\n",
    "\n",
    "# Here, we install libraries which are not already included in Colab.\n",
    "!pip install csbdeep\n",
    "\n",
    "\n",
    "import sys\n",
    "import tensorflow \n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "print(tensorflow.__version__)\n",
    "print(\"Tensorflow enabled.\")\n",
    "\n",
    "\n",
    "from csbdeep.utils import download_and_extract_zip_file, plot_some, axes_dict, plot_history, Path, download_and_extract_zip_file\n",
    "from csbdeep.data import RawData, create_patches \n",
    "from csbdeep.io import load_training_data, save_tiff_imagej_compatible\n",
    "from csbdeep.models import Config, CARE\n",
    "from csbdeep import data\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import shutil \n",
    "from tifffile import imread, imsave\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b792a131",
   "metadata": {},
   "source": [
    "## **2.1. Check for GPU access**\n",
    "---\n",
    "\n",
    "By default, the session should be using Python 3 and GPU acceleration, but it is possible to ensure that these are set properly by doing the following:\n",
    "\n",
    "<font size = 4>Go to **Runtime -> Change the Runtime type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5a252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.test.gpu_device_name()=='':\n",
    "        print('You do not have GPU access.') \n",
    "\n",
    "else:\n",
    "        print('You have GPU access')\n",
    "        subprocess.run([\"nvidia-smi\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf096580",
   "metadata": {},
   "source": [
    "## **2.2. Mount your Google Drive**\n",
    "---\n",
    "In case you want to use the data you acquired during the workshop, you need to mount your Google Drive to this notebook.\n",
    "\n",
    "Play the cell below to mount your Google Drive and follow the link. In the new browser window, select your drive and select 'Allow', copy the code, paste into the cell and press enter. This will give Colab access to the data on the drive. \n",
    "\n",
    "Once this is done, your data are available in the **Files** tab on the top left of notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b2c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@markdown ##Run this cell to connect your Google Drive to Colab\n",
    "\n",
    "#@markdown * Click on the URL. \n",
    "\n",
    "#@markdown * Follow the instructions\n",
    "\n",
    "#@markdown * Click on \"Files\" site on the right. Refresh the site. Your Google Drive folder should now be available here as \"drive\". \n",
    "\n",
    "#mounts user's Google Drive to Google Colab.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dc5b90",
   "metadata": {},
   "source": [
    "## **2.3. Select the inference folder**\n",
    "---\n",
    "Select the **Test_data_folder** (where the noisy images are) and the **Result_folder_root** (where the denoised inferences are going to be saved)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b15e308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown ###Path to denoise images:\n",
    "\n",
    "Test_data_folder = \"\" #@param {type:\"string\"}\n",
    "\n",
    "Result_folder_root = \"\" #@param {type:\"string\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8591bfea",
   "metadata": {},
   "source": [
    "## **3.0. Perform denoising**\n",
    "---\n",
    "Using the pretrained model in **Your_Github_username/MINDLAB-denoising-bioluminescence-images/model** perform the denoising in the images stored in the path selected before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e600e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model_name = \"denoising_model\" #@param {type:\"string\"}\n",
    "inference_model_path = r\"/content/MINDLAB-Denoising-bioluminescence-images/model\"\n",
    "\n",
    "Result_folder = Result_folder_root\n",
    "\n",
    "# Create directories for the results\n",
    "if not os.path.exists(Result_folder):\n",
    "    os.makedirs(Result_folder)\n",
    "else:\n",
    "    shutil.rmtree(Result_folder)\n",
    "    os.makedirs(Result_folder)\n",
    "\n",
    "\n",
    "#Activate the pretrained model. \n",
    "model_training = CARE(config=None, name=inference_model_name, basedir=inference_model_path)\n",
    "\n",
    "STACK = \"N\"\n",
    "# creates a loop, creating filenames and saving them\n",
    "if STACK == \"Y\":\n",
    "    for filename in os.listdir(Test_data_folder):\n",
    "        img = imread(os.path.join(Test_data_folder,filename))\n",
    "        r = np.zeros_like(img)\n",
    "        for s in range(img.shape[0]):\n",
    "            restored = model_training.predict(img[s,:,:], axes='YX')\n",
    "            r[s,:,:] = restored\n",
    "        os.chdir(Result_folder)\n",
    "        imsave(filename,r.astype(\"uint16\"))\n",
    "else:\n",
    "\n",
    "    for filename in os.listdir(Test_data_folder):\n",
    "        img = imread(os.path.join(Test_data_folder,filename))\n",
    "        restored = model_training.predict(img, axes='YX')\n",
    "        os.chdir(Result_folder)\n",
    "        imsave(filename,restored)\n",
    "\n",
    "\n",
    "print(\"Images saved into folder:\", Result_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
